---
title: "Homework #6: SVM and Calibration" 
author: "**Georgia Davidson**"
format: ds6030hw-html
---

```{r config, include=FALSE}
# Set global configurations and settings here
knitr::opts_chunk$set()                 # set global chunk options
ggplot2::theme_set(ggplot2::theme_bw()) # set ggplot2 theme
```

# Required R packages and Directories {.unnumbered .unlisted}

```{r packages, message=FALSE, warning=FALSE}
dir_data= 'https://mdporter.github.io/teaching/data/' # data directory
library(tidyverse)  # functions for data manipulation  
```


# COMPAS Recidivism Prediction

A recidivism risk model called COMPAS was the topic of a [ProPublica article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing/) on ML bias. Because the data and notebooks used for article was released on [github](https://github.com/propublica/compas-analysis), we can also evaluate the prediction bias (i.e., calibration). 

This code will read in the *violent crime* risk score and apply the filtering used in the [analysis](https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb).
```{r, message=FALSE}
#| code-fold: true
library(tidyverse)
df = read_csv("https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years-violent.csv")

risk = df %>% 
  filter(days_b_screening_arrest <= 30) %>%
  filter(days_b_screening_arrest >= -30) %>% 
  filter(is_recid != -1) %>%
  filter(c_charge_degree != "O") %>%
  filter(v_score_text != 'N/A') %>% 
  transmute(
    age, age_cat,
    charge = ifelse(c_charge_degree == "F", "Felony", "Misdemeanor"),
    race,
    sex,                 
    priors_count = priors_count...15,
    score = v_decile_score,              # the risk score {1,2,...,10}
    outcome = two_year_recid...53        # outcome {1 = two year recidivate}
  )
```

The `risk` data frame has the relevant information for completing the problems.



# Problem 1: COMPAS risk score


## a. Risk Score and Probability (table)

Assess the predictive bias in the COMPAS risk scores by evaluating the probability of recidivism, e.g. estimate $\Pr(Y = 1 \mid \text{Score}=x)$. Use any reasonable techniques (including Bayesian) to estimate the probability of recidivism for each risk score. 

Specifically, create a table (e.g., data frame) that provides the following information:

- The COMPASS risk score.
- The point estimate of the probability of recidivism for each risk score.
- 95% confidence or credible intervals for the probability (e.g., Using normal theory, bootstrap, or Bayesian techniques).

Indicate the choices you made in estimation (e.g., state the prior if you used Bayesian methods).

::: {.callout-note title="Solution"}
```{r}
# Fit logistic regression model
model <- glm(outcome ~ score, data = risk, family = binomial)

# Create df for predictions
score_range <- data.frame(score = 1:10)

# Get predictions on the linear scale
predictions <- predict(model, newdata = score_range, type = "link", se.fit = TRUE)

# Convert to probabilities
score_range$prob_recidivism <- plogis(predictions$fit)

# Calculate confidence intervals
z_value <- 1.96 
score_range$lower_ci <- plogis(predictions$fit - z_value * predictions$se.fit)
score_range$upper_ci <- plogis(predictions$fit + z_value * predictions$se.fit)

# View resulting df
score_range

```


:::

## b. Risk Score and Probability (plot)

Make a plot of the risk scores and corresponding estimated probability of recidivism. 

- Put the risk score on the x-axis and estimate probability of recidivism on y-axis.
- Add the 95% confidence or credible intervals calculated in part a.
- Comment on the patterns you see. 

::: {.callout-note title="Solution"}
```{r}
# Plot the results
ggplot(score_range, aes(x = score)) +
  geom_line(aes(y = prob_recidivism), color = "limegreen") +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.2) +
  labs(title = "Probability of Recidivism by COMPAS Risk Score",
       x = "COMPAS Risk Score",
       y = "Estimated Probability of Recidivism") +
  theme_minimal()


# Observations:

# There appears to be a positive exponential relationship between COMPAS risk
# score and estimated probability of recidivism. There don't seem to be any 
# unusual dips or breaks in the graph, although the ribbon does widen as the 
# x value increases. So overall, it seems as though a greater COMPAS risk 
# score tends to correspond with a greater estimated probability of 
# recidivism. 
```


:::

## c. Risk Score and Probability (by race)

Repeat the analysis, but this time do so for every race. Produce a set of plots (one per race) and comment on the patterns. 


::: {.callout-note title="Solution"}
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# List to hold race plots
race_plots <- list()

# Loop through unique races
for (race in unique(risk$race)) {
  # Filter data for the specific race
  race_data <- risk %>% filter(race == !!race)
  
  # Fit logistic regression model
  model <- glm(outcome ~ score, data = race_data, family = binomial)

  # Create df for predictions
  score_range <- data.frame(score = 1:10)
  
  # Get predictions on linear scale
  predictions <- predict(model, newdata = score_range, type = "link", se.fit = TRUE)
  
  # Convert to probabilities
  score_range$prob_recidivism <- plogis(predictions$fit)
  
  # Calculate confidence intervals
  z_value <- 1.96
  score_range$lower_ci <- plogis(predictions$fit - z_value * predictions$se.fit)
  score_range$upper_ci <- plogis(predictions$fit + z_value * predictions$se.fit)
  
  # Generate the plot
  p <- ggplot(score_range, aes(x = score)) +
    geom_line(aes(y = prob_recidivism), color = "purple4", size = 1) +
    geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.2, fill = "lightblue") +
    labs(title = paste("Probability of Recidivism by COMPAS Risk Score for Race:", race),
         x = "COMPAS Risk Score",
         y = "Estimated Probability of Recidivism") +
    theme_minimal()

  # Store the plot in the list
  race_plots[[race]] <- p
}

# Display plots
library(gridExtra)
do.call(grid.arrange, c(race_plots, ncol = 2))

# Comments:

# In all the graphs there seem to be a neutral to positive correlation between
# COMPAS risk score and estimated probability of recidivism. There are unusual
# rises/jumps in the bottom two graphs, while the rest tend to follow a more
# typical exponential pattern. Additionally the bottom two graphs have a very
# large ribbon, whereas the others have smaller ones (and the top right 
# even having next to none.)

```



:::

## d. ROC Curves

Use the raw COMPAS risk scores to make a ROC curve for each race. 

- Are the best discriminating models the ones you expected? 
- Are the ROC curves helpful in evaluating the COMPAS risk score? 

::: {.callout-note title="Solution"}
```{r}
library(pROC)

# List to hold ROC plots
roc_plots <- list()

# Loop through unique races to generate ROC curves
for (race in unique(risk$race)) {
  race_data <- risk %>% filter(race == !!race)
  
  # Create ROC curve
  roc_result <- roc(race_data$outcome, race_data$score)
  
  # Plot the ROC curve
  p <- ggroc(roc_result) +
    labs(title = paste("ROC Curve for Race:", race),
         x = "False Positive Rate",
         y = "True Positive Rate") +
    theme_minimal() +
    annotate("text", x = 0.5, y = 0.2, label = paste("AUC =", round(auc(roc_result), 2)), size = 5)
  
  # Store ROC plot in the list
  roc_plots[[race]] <- p
}

# Display all ROC plots
do.call(grid.arrange, c(roc_plots, ncol = 2))


# Comments: 

# The best discriminating models were basically what I expected, with the
# steepest sloped models having the higher AUC values. While not a perfectly unbiased 
# metric, ROC curves could indeed be used to help evaluate the COMPAS score as 
# a predictive tool for binary outcomes (eg. whether a person will re-offend
# or not), as COMPAS score is plotted on the x axis and we can determine how
# well it predicts the positive class (re-offending) compared to the 
# negative class (not re-offending).


```
:::


# Problem 2: Support Vector Machines (SVM)

Focus on Problem 1, we won't have an SVM problem this week.



    

